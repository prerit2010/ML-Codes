{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNomfIDwd4SNhSO3NgedOnU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prerit2010/ML-Codes/blob/main/addition_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1RKam96zI1m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a list numbers between 0 and 10000\n",
        "a = np.arange(0, 10000, 1)"
      ],
      "metadata": {
        "id": "YcrIHRuxzLNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the dataset for addition of numbers (10000 data points)\n",
        "data = []\n",
        "label = []\n",
        "for i in range(0,10000):\n",
        "    x = np.random.choice(a, 2)\n",
        "    y = x[0] + x[1]\n",
        "    data.append(x)\n",
        "    label.append(y)\n",
        "data = np.array(data)\n",
        "label = np.array(label)"
      ],
      "metadata": {
        "id": "RA8bKDm0z-_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape, label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KagwUb5g0r9P",
        "outputId": "78ba4d66-bf24-4071-bb4d-4bcabc4b02ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 2), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "UX4zbfRz0t9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, label, random_state=1)"
      ],
      "metadata": {
        "id": "XucnVbyk02my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regr = LinearRegression().fit(X_train, y_train)\n",
        "regr.predict(X_test[:2]), y_test[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLIhKwK91S0v",
        "outputId": "3aa416ec-8e6b-48a2-e020-2122247688f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([12215., 10103.]), array([12215, 10103]))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regr = MLPRegressor(random_state=1, max_iter=1000).fit(X_train, y_train)\n",
        "regr.predict(X_test[:2]), y_test[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW96K7DT1gd-",
        "outputId": "158b0643-0bc9-44a1-9ab6-e96619d74200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([12214.63070007, 10103.75403573]), array([12215, 10103]))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# through keras\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "IDIu4old1kCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(1, name=\"layer1\"))"
      ],
      "metadata": {
        "id": "dkZhrLSr7XUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "AUcX3AWb74jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uOjH9THh8FAp",
        "outputId": "aa18ba88-3bf8-4e08-c485-29198b16a6bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0110\n",
            "Epoch 2/1000\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0672\n",
            "Epoch 3/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0198\n",
            "Epoch 4/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3268\n",
            "Epoch 5/1000\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0687\n",
            "Epoch 6/1000\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0641\n",
            "Epoch 7/1000\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1999\n",
            "Epoch 8/1000\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.4072\n",
            "Epoch 9/1000\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2592\n",
            "Epoch 10/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0011\n",
            "Epoch 11/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0015\n",
            "Epoch 12/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0113\n",
            "Epoch 13/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.1825\n",
            "Epoch 14/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0219\n",
            "Epoch 15/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.5250\n",
            "Epoch 16/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 9.6818e-04\n",
            "Epoch 17/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.6079e-04\n",
            "Epoch 18/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.5800\n",
            "Epoch 19/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 5.3459e-04\n",
            "Epoch 20/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.6004e-04\n",
            "Epoch 21/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 22/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.6348\n",
            "Epoch 23/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.6297e-04\n",
            "Epoch 24/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0021\n",
            "Epoch 25/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0030\n",
            "Epoch 26/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4306\n",
            "Epoch 27/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.1078\n",
            "Epoch 28/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.6787e-04\n",
            "Epoch 29/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 8.0566e-04\n",
            "Epoch 30/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.0381\n",
            "Epoch 31/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.1957e-05\n",
            "Epoch 32/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.2140e-05\n",
            "Epoch 33/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.3386e-05\n",
            "Epoch 34/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.6449e-05\n",
            "Epoch 35/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0182\n",
            "Epoch 36/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.5162\n",
            "Epoch 37/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0024\n",
            "Epoch 38/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.3808e-04\n",
            "Epoch 39/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0879\n",
            "Epoch 40/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.2415\n",
            "Epoch 41/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.2121e-06\n",
            "Epoch 42/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 7.7629e-06\n",
            "Epoch 43/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 7.9437e-06\n",
            "Epoch 44/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 8.8955e-06\n",
            "Epoch 45/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.3240e-05\n",
            "Epoch 46/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 7.6394e-05\n",
            "Epoch 47/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.1108\n",
            "Epoch 48/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2491\n",
            "Epoch 49/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0020\n",
            "Epoch 50/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.9242e-04\n",
            "Epoch 51/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.7352\n",
            "Epoch 52/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.8777e-05\n",
            "Epoch 53/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.9634e-06\n",
            "Epoch 54/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 5.0264e-05\n",
            "Epoch 55/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4756\n",
            "Epoch 56/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0097\n",
            "Epoch 57/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.5155e-05\n",
            "Epoch 58/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.1660\n",
            "Epoch 59/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0130\n",
            "Epoch 60/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3136\n",
            "Epoch 61/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0023\n",
            "Epoch 62/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.4618e-04\n",
            "Epoch 63/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.1046\n",
            "Epoch 64/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4901\n",
            "Epoch 65/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.1017e-05\n",
            "Epoch 66/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0019\n",
            "Epoch 67/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.5572\n",
            "Epoch 68/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0052\n",
            "Epoch 69/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 9.9947e-06\n",
            "Epoch 70/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.0412e-05\n",
            "Epoch 71/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3303\n",
            "Epoch 72/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.1171e-04\n",
            "Epoch 73/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3064\n",
            "Epoch 74/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0726\n",
            "Epoch 75/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.9252e-05\n",
            "Epoch 76/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.3709e-04\n",
            "Epoch 77/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.9150\n",
            "Epoch 78/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 4.1769e-06\n",
            "Epoch 79/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 5.8339e-06\n",
            "Epoch 80/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.9002e-05\n",
            "Epoch 81/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0133\n",
            "Epoch 82/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.5516\n",
            "Epoch 83/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0011\n",
            "Epoch 84/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.5968e-06\n",
            "Epoch 85/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.2944e-06\n",
            "Epoch 86/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 4.0844e-06\n",
            "Epoch 87/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.0126e-05\n",
            "Epoch 88/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.5266e-04\n",
            "Epoch 89/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2416\n",
            "Epoch 90/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0010\n",
            "Epoch 91/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4324\n",
            "Epoch 92/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4764\n",
            "Epoch 93/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.0172e-06\n",
            "Epoch 94/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 4.5005e-06\n",
            "Epoch 95/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.8631e-04\n",
            "Epoch 96/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.6262e-04\n",
            "Epoch 97/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2518\n",
            "Epoch 98/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2662\n",
            "Epoch 99/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0027\n",
            "Epoch 100/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.6078e-05\n",
            "Epoch 101/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.5025\n",
            "Epoch 102/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.3347e-05\n",
            "Epoch 103/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 8.9074e-04\n",
            "Epoch 104/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2886\n",
            "Epoch 105/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0350\n",
            "Epoch 106/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0137\n",
            "Epoch 107/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2527\n",
            "Epoch 108/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0394\n",
            "Epoch 109/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0373\n",
            "Epoch 110/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.1986\n",
            "Epoch 111/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.8025e-06\n",
            "Epoch 112/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.3564e-06\n",
            "Epoch 113/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 5.2382e-06\n",
            "Epoch 114/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.0374e-04\n",
            "Epoch 115/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 4.6719e-05\n",
            "Epoch 116/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4124\n",
            "Epoch 117/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.9248e-04\n",
            "Epoch 118/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.1068e-04\n",
            "Epoch 119/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.8997\n",
            "Epoch 120/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.9341e-05\n",
            "Epoch 121/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.0264e-06\n",
            "Epoch 122/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.6304e-06\n",
            "Epoch 123/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.9796e-06\n",
            "Epoch 124/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.3607e-06\n",
            "Epoch 125/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 5.5068e-06\n",
            "Epoch 126/1000\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 9.2123e-06\n",
            "Epoch 127/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.3414e-05\n",
            "Epoch 128/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4204\n",
            "Epoch 129/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.6707e-04\n",
            "Epoch 130/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0037\n",
            "Epoch 131/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.1514\n",
            "Epoch 132/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.5374\n",
            "Epoch 133/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.1090\n",
            "Epoch 134/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.4105e-05\n",
            "Epoch 135/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.7038e-04\n",
            "Epoch 136/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0900\n",
            "Epoch 137/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2271\n",
            "Epoch 138/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.9299e-04\n",
            "Epoch 139/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.1744\n",
            "Epoch 140/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0060\n",
            "Epoch 141/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.8305\n",
            "Epoch 142/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.8611e-05\n",
            "Epoch 143/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 4.8950e-06\n",
            "Epoch 144/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0012\n",
            "Epoch 145/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.0620\n",
            "Epoch 146/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2678\n",
            "Epoch 147/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.7723e-06\n",
            "Epoch 148/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.3272e-06\n",
            "Epoch 149/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.8392e-06\n",
            "Epoch 150/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 8.0849e-05\n",
            "Epoch 151/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 4.8277e-05\n",
            "Epoch 152/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3234\n",
            "Epoch 153/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0016\n",
            "Epoch 154/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0390\n",
            "Epoch 155/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3823\n",
            "Epoch 156/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 157/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2226\n",
            "Epoch 158/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0037\n",
            "Epoch 159/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.5878e-04\n",
            "Epoch 160/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2190\n",
            "Epoch 161/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0237\n",
            "Epoch 162/1000\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 1.1154\n",
            "Epoch 163/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 5.2643e-06\n",
            "Epoch 164/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 4.3627e-06\n",
            "Epoch 165/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.2059e-05\n",
            "Epoch 166/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.2035e-05\n",
            "Epoch 167/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.1136\n",
            "Epoch 168/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0229\n",
            "Epoch 169/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2268\n",
            "Epoch 170/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0776\n",
            "Epoch 171/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.5885\n",
            "Epoch 172/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2714\n",
            "Epoch 173/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.6053e-06\n",
            "Epoch 174/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.0582e-06\n",
            "Epoch 175/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.3110e-05\n",
            "Epoch 176/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3947\n",
            "Epoch 177/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0195\n",
            "Epoch 178/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.5865e-04\n",
            "Epoch 179/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.1257\n",
            "Epoch 180/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.1863\n",
            "Epoch 181/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2202\n",
            "Epoch 182/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 7.2727e-05\n",
            "Epoch 183/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0011\n",
            "Epoch 184/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.8574\n",
            "Epoch 185/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 7.5679e-05\n",
            "Epoch 186/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 4.2730e-06\n",
            "Epoch 187/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.2325e-06\n",
            "Epoch 188/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0029\n",
            "Epoch 189/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.1726\n",
            "Epoch 190/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0584\n",
            "Epoch 191/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.6698\n",
            "Epoch 192/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 193/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 8.2422e-06\n",
            "Epoch 194/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 5.4477e-05\n",
            "Epoch 195/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4893\n",
            "Epoch 196/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0410\n",
            "Epoch 197/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.3883e-06\n",
            "Epoch 198/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.5271e-04\n",
            "Epoch 199/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.6067\n",
            "Epoch 200/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0864\n",
            "Epoch 201/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 7.2412e-06\n",
            "Epoch 202/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.6939e-05\n",
            "Epoch 203/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0036\n",
            "Epoch 204/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4911\n",
            "Epoch 205/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0633\n",
            "Epoch 206/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.8861e-05\n",
            "Epoch 207/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0336\n",
            "Epoch 208/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.1604\n",
            "Epoch 209/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.1403\n",
            "Epoch 210/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4549\n",
            "Epoch 211/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.7040e-06\n",
            "Epoch 212/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.6405e-05\n",
            "Epoch 213/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3958\n",
            "Epoch 214/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.7751e-05\n",
            "Epoch 215/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.4876e-04\n",
            "Epoch 216/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2027\n",
            "Epoch 217/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.5819\n",
            "Epoch 218/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.4750e-05\n",
            "Epoch 219/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.7432e-09\n",
            "Epoch 220/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.3379e-10\n",
            "Epoch 221/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.3379e-10\n",
            "Epoch 222/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.3379e-10\n",
            "Epoch 223/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.3332e-10\n",
            "Epoch 224/1000\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 3.3332e-10\n",
            "Epoch 225/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.2984e-10\n",
            "Epoch 226/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.2897e-10\n",
            "Epoch 227/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.2897e-10\n",
            "Epoch 228/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.1814e-10\n",
            "Epoch 229/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.8536e-10\n",
            "Epoch 230/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.8502e-10\n",
            "Epoch 231/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.8253e-10\n",
            "Epoch 232/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.8163e-10\n",
            "Epoch 233/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.3461e-10\n",
            "Epoch 234/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.7385e-11\n",
            "Epoch 235/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.7385e-11\n",
            "Epoch 236/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.7385e-11\n",
            "Epoch 237/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.7385e-11\n",
            "Epoch 238/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.7385e-11\n",
            "Epoch 239/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.7167e-11\n",
            "Epoch 240/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.7167e-11\n",
            "Epoch 241/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.7167e-11\n",
            "Epoch 242/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.5677e-11\n",
            "Epoch 243/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.5305e-11\n",
            "Epoch 244/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.5150e-11\n",
            "Epoch 245/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.5150e-11\n",
            "Epoch 246/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 1.1673e-11\n",
            "Epoch 247/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 7.4506e-13\n",
            "Epoch 248/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 7.4506e-13\n",
            "Epoch 249/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 7.4506e-13\n",
            "Epoch 250/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 7.4506e-13\n",
            "Epoch 251/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 7.4506e-13\n",
            "Epoch 252/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 7.4506e-13\n",
            "Epoch 253/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 7.4506e-13\n",
            "Epoch 254/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 7.4506e-13\n",
            "Epoch 255/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 7.4506e-13\n",
            "Epoch 256/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 7.4506e-13\n",
            "Epoch 257/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.5193e-13\n",
            "Epoch 258/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.5193e-13\n",
            "Epoch 259/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.5193e-13\n",
            "Epoch 260/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 6.5193e-13\n",
            "Epoch 261/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 2.7940e-13\n",
            "Epoch 262/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.1044e-14\n",
            "Epoch 263/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.1044e-14\n",
            "Epoch 264/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.1044e-14\n",
            "Epoch 265/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.1044e-14\n",
            "Epoch 266/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.1044e-14\n",
            "Epoch 267/1000\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 3.1044e-14\n",
            "Epoch 268/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.1044e-14\n",
            "Epoch 269/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.1044e-14\n",
            "Epoch 270/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.1044e-14\n",
            "Epoch 271/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.1044e-14\n",
            "Epoch 272/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.1044e-14\n",
            "Epoch 273/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.1044e-14\n",
            "Epoch 274/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.1044e-14\n",
            "Epoch 275/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 3.1044e-14\n",
            "Epoch 276/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
            "Epoch 277/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
            "Epoch 278/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
            "Epoch 279/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
            "Epoch 280/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
            "Epoch 281/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
            "Epoch 282/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
            "Epoch 283/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
            "Epoch 284/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
            "Epoch 285/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
            "Epoch 286/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
            "Epoch 287/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
            "Epoch 288/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
            "Epoch 289/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
            "Epoch 290/1000\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
            "Epoch 291/1000\n",
            "149/235 [==================>...........] - ETA: 0s - loss: 0.0000e+00"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-e781fa656f1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "770ABqJ18GeP",
        "outputId": "24417391-9421-406a-9dbb-d08760cfcb3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer1 (Dense)              (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_test[:5]), y_test[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxSCqC8K8Mrr",
        "outputId": "d36506d1-f154-4d7b-906b-26f2df679656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[12215.],\n",
              "        [10103.],\n",
              "        [12421.],\n",
              "        [ 8814.],\n",
              "        [11301.]], dtype=float32), array([12215, 10103, 12421,  8814, 11301]))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZVwm0KeOCXum"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}